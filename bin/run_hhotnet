#!/usr/bin/env nextflow

params.out = "."
params.N = 100

tab2 = file(params.tab2)
vegas = file(params.scores)
hhnet_path = file(params.hhnet_path)

process make_network {

    input:
        file TAB2 from tab2

    output:
        file 'node_index.tsv' into node_index_3, node_index_4, node_index_5
        file 'edge_list.tsv' into edge_list_1, edge_list_2, edge_list_3, edge_list_5

    script:
    template 'io/tab2_2hotnet.R'

}

process vegas2hotnet {

    input:
        file VEGAS from vegas

    output:
        file 'scores.ht' into scores_perm, scores_bins, scores_anal

    script:
    template 'io/vegas2hotnet.R'

}

process construct_similarity_matrix {

    input:
        file EDGE_LIST from edge_list_1
        file HHNET from hhnet_path

    output:
        file 'similarity_matrix.h5' into similarity

    """
    python ${HHNET}/construct_similarity_matrix.py \
-i   ${EDGE_LIST} \
-o   similarity_matrix.h5
    """

}

process find_permutation_bins {

    input:
        file HHNET from hhnet_path
        file SCORES from scores_perm
        file NODE_INDEX from node_index_3
        file EDGE_LIST from edge_list_3

    output:
        file 'score_bins.tsv' into bins

    """
    python ${HHNET}/find_permutation_bins.py \
-gsf ${SCORES} \
-igf ${NODE_INDEX} \
-elf ${EDGE_LIST} \
-ms  1000 \
-o   score_bins.tsv
    """

}

process permute_scores {

    input:
        file HHNET from hhnet_path
        each I from 1..params.N
        file SCORES from scores_bins
        file BINS from bins

    output:
        set val(I),"scores_permutation_${I}.tsv" into score_perms

    """
    python ${HHNET}/permute_scores.py \
-i  ${SCORES} \
-bf ${BINS} \
-s  ${I} \
-o  scores_permutation_${I}.tsv
    """

}

all_scores = scores_anal. map {it->[ 0, it]} .mix(score_perms)

process construct_hierarchy {

    input:
        file HHNET from hhnet_path
        file SIMILARITY from similarity
        set I,file(SCORES) from all_scores
        file NODE_INDEX from node_index_4

    output:
        file "hierarchy_edge_list_${I}" into h_edges
        file "hierarchy_index_list_${I}" into h_idx

    """
    python ${HHNET}/construct_hierarchy.py \
-smf  ${SIMILARITY} \
-igf  ${NODE_INDEX} \
-gsf  ${SCORES} \
-helf hierarchy_edge_list_${I} \
-higf hierarchy_index_list_${I}
    """

}

process process_hierarchies {

    publishDir "$params.out", overwrite: true, mode: "copy"

    input:
        file HHNET from hhnet_path
        file '*' from h_idx.collect()
        file '*' from h_edges.collect()

    output:
        file 'clusters.tsv' into clusters
        file 'sizes.pdf'

    """
    python ${HHNET}/process_hierarchies.py \
-oelf hierarchy_edge_list_0 \
-oigf hierarchy_index_list_0 \
-pelf \$(for i in `seq ${params.N}`; do echo " hierarchy_edge_list_\$i"; done) \
-pigf \$(for i in `seq ${params.N}`; do echo " hierarchy_index_list_\$i"; done) \
-cf   selected_genes.hotnet.txt \
-pl   network score \
-pf   cluster_sizes.hotnet.pdf
    """

}
